{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import sys; sys.path.insert(0, \"../utils/\")\n",
    "from data_utils import get_data_location, get_clinical_df, get_bluepoints_df, get_manual_severity_scores\n",
    "from ml_pipeline import ModelEvaluation, highlight_max\n",
    "\n",
    "DATA_PATH = get_data_location()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load yolo_detections_df if it already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"yolo_detection_df.csv\"):\n",
    "    yolo_detection_df = pd.read_csv(\"yolo_detection_df.csv\")\n",
    "else:\n",
    "    print(\"Yolo file does not exist\")\n",
    "\n",
    "if os.path.exists(\"df.csv\"):\n",
    "    df = pd.read_csv(\"df.csv\")\n",
    "else:\n",
    "    print(\"df file does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load Roy data for Frame comparison\n",
    "# pixel_count_path = os.path.join(DATA_PATH,\"cropped_videos_segmented/post_processing\")\n",
    "\n",
    "# # List all files & directories\n",
    "# files = os.listdir(pixel_count_path)\n",
    "\n",
    "# # keep only .csv files\n",
    "# csvs = [x for x in files if x.endswith(\".gif_pixel_counts.csv\")]\n",
    "\n",
    "# # Read all csvs into one dataframe\n",
    "# df = pd.concat((pd.read_csv(os.path.join(pixel_count_path, f)) for f in csvs))\n",
    "\n",
    "# yolo_df_frames = yolo_detection_df[[\"video_name\", \"Frame\"]].drop_duplicates().groupby(\"video_name\").count()\n",
    "# roy_df_frames = df[[\"video_name\", \"Frame\"]].drop_duplicates().groupby(\"video_name\").count()\n",
    "# yolo_df_frames = yolo_df_frames.rename(columns={\"Frame\": \"yolo_frames\"})\n",
    "# roy_df_frames = roy_df_frames.rename(columns={\"Frame\": \"roy_frames\"})\n",
    "\n",
    "# frames_df = yolo_df_frames.merge(roy_df_frames, on=\"video_name\")\n",
    "# frames_df[\"frame_diff\"] = frames_df[\"yolo_frames\"] - frames_df[\"roy_frames\"]\n",
    "# frames_df[\"frame_diff\"] = frames_df[\"frame_diff\"].abs()\n",
    "# print(frames_df[\"frame_diff\"].describe())\n",
    "\n",
    "# yolo_frames = yolo_df_frames.sum().values[0]\n",
    "# all_frames = roy_df_frames.sum().values[0]\n",
    "\n",
    "# print(\"Yolo frames: \", yolo_frames)\n",
    "# print(\"All frames: \", all_frames)\n",
    "# # Removed frames\n",
    "# print(\"Removed frames: \", all_frames - yolo_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add manual severity labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_manual = get_manual_severity_scores()\n",
    "\n",
    "# Merge manual severity scores with yolo severity scores\n",
    "yolo_detection_df = yolo_detection_df.merge(severity_manual[[\"video_name\", \"Severity Score\"]], on=\"video_name\", how=\"left\")\n",
    "\n",
    "# Rename Severity Score to manual_severity_score\n",
    "yolo_detection_df.rename(columns={\"Severity Score\": \"manual_severity_score\"}, inplace=True)\n",
    "\n",
    "# Plot number of discarded rows due to missing manual severity scores\n",
    "print(\"Number of discarded frames due to missing manual severity scores: {}\".format(len(yolo_detection_df[yolo_detection_df[\"manual_severity_score\"].isna()])))\n",
    "\n",
    "# Drop all rows where the manual severity score is not available\n",
    "yolo_detection_df = yolo_detection_df.dropna(subset=[\"manual_severity_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the class names from the yolo net\n",
    "\n",
    "# Class names: ['0: Airbronchograms', '1: Alines', '2: Blines', '3: Bpatch', '4: Consolidations', '5: Pleura', '6: Rib', '7: Shadow']\n",
    "class_names = [\"Airbronchograms\", \"Alines\", \"Blines\", \"Bpatch\", \"Consolidations\", \"Pleura\", \"Rib\", \"Shadow\"]\n",
    "class_name_2_idx = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "idx_2_class_name = {idx: class_name for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "# yolo_detection_df[\"class_name\"] = yolo_detection_df[\"class\"].apply(lambda x: class_names[x])\n",
    "\n",
    "idx_2_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataframe contains one row per object detected by the YOLONet in all frames of all bluepoint-videos of all patients\n",
    "# The columns are:\n",
    "# - class: the class of the object detected by the YOLONet\n",
    "# - confidence: the confidence of the YOLONet in the detection\n",
    "# - x: the x-coordinate of the center of the bounding box\n",
    "# - y: the y-coordinate of the center of the bounding box\n",
    "# - w: the width of the bounding box\n",
    "# - h: the height of the bounding box\n",
    "# - area: the area of the bounding box\n",
    "# - video_name: the name of the video\n",
    "# - Frame: the frame number\n",
    "#...\n",
    "# - Patient ID: the ID of the patient\n",
    "# - Bluepoint: the name of the bluepoint\n",
    "# - COVID19: the clinical diagnosis of the patient\n",
    "# - yolo_quality_score: the quality score of the YOLONet\n",
    "# - yolo_quality: the quality of the YOLONet\n",
    "# - yolo_severity_score: the severity score of the YOLONet\n",
    "# - class_name: the name of the class\n",
    "yolo_detection_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_detection_df[\"yolo_quality_score\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_name_grp = yolo_detection_df[[\"video_name\",\"Frame\", \"class_name\"]].drop_duplicates().groupby([\"video_name\",\"Frame\"])\n",
    "\n",
    "# # For all class names in class_names count the frames in which the class name is present\n",
    "# class_name_counts = class_name_grp[\"class_name\"].value_counts().unstack().fillna(0)\n",
    "# # Sum up all counts for all class names\n",
    "# class_name_counts.sum(axis=0) / yolo_frames * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Severity Score analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical test to check whether the COVID cases have on average different severity scores\n",
    "from scipy import stats as st\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "# Frame-wise severity score\n",
    "frame_level = yolo_detection_df.groupby([\"Frame\", \"video_name\"]).first().reset_index().drop(columns=[\"class\", \"confidence\", \"x\", \"y\", \"w\", \"h\", \"area\", \"class_name\"])\n",
    "\n",
    "# Filter out frames with low quality\n",
    "severity_filtered = frame_level[frame_level.yolo_severity_score >= 0]\n",
    "x0 = severity_filtered[severity_filtered[\"COVID19\"] == 0][\"yolo_severity_score\"]\n",
    "x1 = severity_filtered[severity_filtered[\"COVID19\"] == 1][\"yolo_severity_score\"]\n",
    "\n",
    "# T-Test for independent samples\n",
    "ttest = st.ttest_ind(a=x0, b=x1, equal_var=True)\n",
    "print(f\"T-Test: statistic={ttest.statistic:.4f}, p-value={ttest.pvalue:.4f}\")\n",
    "\n",
    "# Mann-Whitney U-Test\n",
    "stat, p_value = mannwhitneyu(x0, x1)\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "\n",
    "# Print green if p-value is significant otherwise red\n",
    "if p_value < 0.05:\n",
    "    print(\"\\033[92mSignificant difference\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[91mNo significant difference\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions are significantly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#set seaborn plotting aesthetics as default\n",
    "sns.set(font_scale=1.5)\n",
    "#define plotting region \n",
    "# fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# #Create different views of the severity score against the COVID19 diagnosis\n",
    "# sns.boxplot(data=severity_filtered, x='COVID19', y='yolo_severity_score', ax=axes[0,0]).set(title='Boxplot')\n",
    "# sns.histplot(data=severity_filtered, x='yolo_severity_score', hue='COVID19', bins=4, ax=axes[0,1]).set(title='Histogram')\n",
    "# sns.histplot(data=severity_filtered, x='yolo_severity_score', hue='COVID19', bins=4, stat='density', common_norm=False, ax=axes[1,0]).set(title='Density')\n",
    "# sns.kdeplot(x='yolo_severity_score', data=severity_filtered, hue='COVID19', common_norm=False, ax=axes[1,1]).set(title='KDE')\n",
    "# plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "#Create boxplot and density plot views of the severity score against the COVID19 diagnosis\n",
    "sns.boxplot(data=severity_filtered, x='COVID19', y='yolo_severity_score', ax=axes[0]).set(title='Boxplot', xlabel='COVID-19', ylabel='covEcho Severity Score')\n",
    "# Set y-axis to 0, 1, 2, 3, 4\n",
    "axes[0].set_yticks([0, 1, 2, 3, 4])\n",
    "sns.histplot(data=severity_filtered, x='yolo_severity_score', hue='COVID19', bins=4, stat='density', common_norm=False, ax=axes[1], discrete=True).set(title='Density', xlabel='covEcho Severity Score', ylabel='Density')\n",
    "\n",
    "# sns.boxplot(data=severity_filtered, x='COVID19', y='yolo_severity_score', ax=0 ).set(title='Boxplot', xlabel='COVID-19', ylabel='covEcho Severity Score')\n",
    "# sns.histplot(data=severity_filtered, x='yolo_severity_score', hue='COVID19', bins=4, stat='density', common_norm=False, ax=1).set(title='Density', xlabel='covEcho Severity Score', ylabel='Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlate covid with severity score\n",
    "corr = severity_filtered.yolo_severity_score.corr(severity_filtered.COVID19)\n",
    "print(f\"Correlation between severity score and COVID19 diagnosis: {corr:.4f}\")\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "#Calculate Spearman Rank correlation and corresponding p-value\n",
    "rho, p = spearmanr(severity_filtered['yolo_severity_score'], severity_filtered['COVID19'])\n",
    "print(f\"Spearman Rank correlation: rho={rho:.4f}, p-value={p:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation is not very high. From the plot there seem to be a lot of FP and FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with severity manual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing severity scores\n",
    "severity_comparison = severity_filtered[~severity_filtered[\"manual_severity_score\"].isna()]\n",
    "# Only keep rows with yolo severity scores >= 0\n",
    "severity_comparison = severity_comparison[severity_comparison[\"yolo_severity_score\"] >= 0]\n",
    "# Select only the columns of interest\n",
    "severity_comparison = severity_comparison[[\"Patient ID\", \"Patient ID\", \"video_name\", \"yolo_severity_score\", \"manual_severity_score\", \"COVID19\"]]\n",
    "# Drop duplicates\n",
    "severity_comparison = severity_comparison.drop_duplicates()\n",
    "\n",
    "severity_comparison.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seaborn plotting aesthetics as default\n",
    "sns.set()\n",
    "#define plotting region \n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "#Create different views of the severity score against the COVID19 diagnosis\n",
    "sns.boxplot(data=severity_comparison, x='COVID19', y='manual_severity_score', ax=axes[0,0]).set(title='Boxplot')\n",
    "sns.histplot(data=severity_comparison, x='manual_severity_score', hue='COVID19', bins=4, ax=axes[0,1]).set(title='Histogram')\n",
    "sns.histplot(data=severity_comparison, x='manual_severity_score', hue='COVID19', bins=4, stat='density', common_norm=False, ax=axes[1,0]).set(title='Density')\n",
    "sns.kdeplot(x='manual_severity_score', data=severity_comparison, hue='COVID19', common_norm=False, ax=axes[1,1]).set(title='KDE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlate manual severity scores with yolo severity scores\n",
    "severity_comparison.yolo_severity_score.corr(severity_comparison[\"manual_severity_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "#Calculate Spearman Rank correlation and corresponding p-value\n",
    "rho, p = spearmanr(severity_comparison['yolo_severity_score'], severity_comparison['manual_severity_score'])\n",
    "\n",
    "#Print Spearman rank correlation and p-value\n",
    "print(f\"Spearman Rank correlation: rho={rho:.4f}, p-value={p:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap creation\n",
    "pair_counts = severity_comparison[[\"yolo_severity_score\", \"manual_severity_score\"]].value_counts().reset_index().rename(columns={0: \"count\"})\n",
    "# Convert columns to int\n",
    "pair_counts[\"yolo_severity_score\"] = pair_counts[\"yolo_severity_score\"].astype(int)\n",
    "pair_counts[\"manual_severity_score\"] = pair_counts[\"manual_severity_score\"].astype(int)\n",
    "\n",
    "pair_counts = pair_counts.pivot(index='manual_severity_score', columns='yolo_severity_score', values='count').fillna(0)\n",
    "pair_counts = pair_counts.reindex(index=pair_counts.index[::-1])\n",
    "# Convert all columns to int\n",
    "for col in pair_counts.columns:\n",
    "    pair_counts[col] = pair_counts[col].astype(int)\n",
    "\n",
    "\n",
    "#Plot different views of the yolo severity score against the original severity score\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Heatmap\n",
    "sns.heatmap(pair_counts, annot=True, cmap=\"YlGnBu\", fmt=\"d\", ax=axes[0]).set(title='Heatmap')\n",
    "\n",
    "# KDE plot\n",
    "# sns.kdeplot(x='yolo_severity_score', y='manual_severity_score', data=severity_comparison, shade=True, ax=axes[1]).set(title='KDE')\n",
    "# KDE plot with covid\n",
    "sns.kdeplot(x='yolo_severity_score', y='manual_severity_score', data=severity_comparison, hue='COVID19', ax=axes[1]).set(title='KDE with COVID-19')\n",
    "for ax in axes:\n",
    "    # set y axis label\n",
    "    ax.set_ylabel('Manual Severity Score')\n",
    "    ax.set_xlabel('covEcho Severity Score')\n",
    "\n",
    "plt.suptitle(\"Comparison Plot of covEcho Severity Score and Manual Severity Score\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot only heatmap\n",
    "sns.heatmap(pair_counts, \n",
    "    annot=True, \n",
    "    cmap=\"YlGnBu\", \n",
    "    fmt=\"d\").set(title='Heatmap', xlabel='covEcho Severity Score', ylabel='Manual Severity Score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Patient level severity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_level_df = severity_filtered[[\"Patient ID\", \"Bluepoint\", \"video_name\", \"COVID19\", \"yolo_severity_score\", \"Frame\", \"manual_severity_score\"]].sort_values(by=[\"Patient ID\", \"Bluepoint\", \"Frame\"]).drop_duplicates()\n",
    "# patient_level_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out severity scores < 0\n",
    "patient_level_df = patient_level_df[patient_level_df[\"yolo_severity_score\"] >= 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_grp = patient_level_df.groupby(\"Patient ID\")\n",
    "\n",
    "severity_mean = patient_grp.yolo_severity_score.mean().rename(\"yolo_severity_score_mean\")\n",
    "severtiy_sum = patient_grp.yolo_severity_score.sum().rename(\"yolo_severity_score_sum\")\n",
    "severity_max = patient_grp.yolo_severity_score.max().rename(\"yolo_severity_score_max\")\n",
    "severity_std = patient_grp.yolo_severity_score.std().rename(\"yolo_severity_score_std\")\n",
    "covid = patient_grp.COVID19.first()\n",
    "accumulation_df = pd.concat([severity_mean, severtiy_sum, severity_max, severity_std, covid], axis=1)\n",
    "\n",
    "corr_mean = accumulation_df.COVID19.corr(accumulation_df.yolo_severity_score_mean)\n",
    "corr_sum = accumulation_df.COVID19.corr(accumulation_df.yolo_severity_score_sum)\n",
    "corr_max = accumulation_df.COVID19.corr(accumulation_df.yolo_severity_score_max)\n",
    "corr_std = accumulation_df.COVID19.corr(accumulation_df.yolo_severity_score_std)\n",
    "\n",
    "# Calculate Spearman Rank correlation and corresponding p-value\n",
    "rho_mean, p_mean = spearmanr(accumulation_df['yolo_severity_score_mean'], accumulation_df['COVID19'])\n",
    "rho_sum, p_sum = spearmanr(accumulation_df['yolo_severity_score_sum'], accumulation_df['COVID19'])\n",
    "rho_max, p_max = spearmanr(accumulation_df['yolo_severity_score_max'], accumulation_df['COVID19'])\n",
    "rho_std, p_std = spearmanr(accumulation_df['yolo_severity_score_std'], accumulation_df['COVID19'])\n",
    "\n",
    "# Put all into a df\n",
    "corr_df = pd.DataFrame({\"Correlation\": [corr, corr_mean, corr_sum, corr_max, corr_std],\n",
    "                        \"Spearman Rank correlation\": [rho, rho_mean, rho_sum, rho_max, rho_std],\n",
    "                        # \"p-value\": [p, p_mean, p_sum, p_max, p_std]\n",
    "                        },\n",
    "                          index=[\"Severity\", \"Severity_mean\", \"Severity_sum\", \"Severity_max\", \"Severity_std\"])\n",
    "\n",
    "corr_df.style.apply(highlight_max).format(\"{:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations of the severtiy score with covid are significantly higher on patient level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for the manual severity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop patients with no manual severity score\n",
    "patient_level_df_manual = patient_level_df[patient_level_df[\"manual_severity_score\"].notna()]\n",
    "# Drop frames column and drop duplicates\n",
    "patient_level_df_manual = patient_level_df_manual[[\"Patient ID\", \"Bluepoint\", \"video_name\", \"COVID19\", \"manual_severity_score\"]].sort_values(by=[\"Patient ID\", \"Bluepoint\"]).drop_duplicates()\n",
    "patient_level_df_manual.reset_index(drop=True, inplace=True)\n",
    "patient_level_df_manual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "patient_grp_manual = patient_level_df_manual.groupby(\"Patient ID\")\n",
    "\n",
    "severity_mean = patient_grp_manual.manual_severity_score.mean().rename(\"manual_severity_score_mean\")\n",
    "severtiy_sum = patient_grp_manual.manual_severity_score.sum().rename(\"manual_severity_score_sum\")\n",
    "severity_max = patient_grp_manual.manual_severity_score.max().rename(\"manual_severity_score_max\")\n",
    "severity_std = patient_grp_manual.manual_severity_score.std().rename(\"manual_severity_score_std\")\n",
    "covid = patient_grp_manual.COVID19.first()\n",
    "accumulation_df_manual = pd.concat([severity_mean, severtiy_sum, severity_max, severity_std, covid], axis=1)\n",
    "\n",
    "corr = patient_level_df_manual.manual_severity_score.corr(patient_level_df_manual.COVID19)\n",
    "corr_mean = accumulation_df_manual.COVID19.corr(accumulation_df_manual.manual_severity_score_mean)\n",
    "corr_sum = accumulation_df_manual.COVID19.corr(accumulation_df_manual.manual_severity_score_sum)\n",
    "corr_max = accumulation_df_manual.COVID19.corr(accumulation_df_manual.manual_severity_score_max)\n",
    "corr_std = accumulation_df_manual.COVID19.corr(accumulation_df_manual.manual_severity_score_std)\n",
    "\n",
    "# Calculate Spearman Rank correlation and corresponding p-value\n",
    "rho, p = spearmanr(patient_level_df_manual['manual_severity_score'], patient_level_df_manual['COVID19'])\n",
    "rho_mean, p_mean = spearmanr(accumulation_df_manual['manual_severity_score_mean'], accumulation_df_manual['COVID19'])\n",
    "rho_sum, p_sum = spearmanr(accumulation_df_manual['manual_severity_score_sum'], accumulation_df_manual['COVID19'])\n",
    "rho_max, p_max = spearmanr(accumulation_df_manual['manual_severity_score_max'], accumulation_df_manual['COVID19'])\n",
    "rho_std, p_std = spearmanr(accumulation_df_manual['manual_severity_score_std'], accumulation_df_manual['COVID19'])\n",
    "\n",
    "# Put all into a df\n",
    "corr_df = pd.DataFrame({\"Correlation\": [corr, corr_mean, corr_sum, corr_max, corr_std],\n",
    "                        \"Spearman Rank correlation\": [rho, rho_mean, rho_sum, rho_max, rho_std],\n",
    "                        # \"p-value\": [p, p_mean, p_sum, p_max, p_std]\n",
    "                        },\n",
    "                          index=[\"Severity\", \"Severity_mean\", \"Severity_sum\", \"Severity_max\", \"Severity_std\"])\n",
    "\n",
    "corr_df.style.apply(highlight_max).format(\"{:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add n_largest mean as aggregation strategy. \n",
    "That the max performs worse than the mean can be seen as supporting the hypothesis that looking at a single predicted frame is not very informative both since:\n",
    "1. the models performance is noisy and makes many missclassifications.\n",
    "2. The videos have many uninformative frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get min length of the videos\n",
    "min_length = patient_grp.count().video_name.min()\n",
    "max_length = patient_grp.count().video_name.max()\n",
    "\n",
    "n_largest = []\n",
    "covid = patient_grp.COVID19.first()\n",
    "for i in range(1, max_length):\n",
    "    mean_largest = patient_grp.yolo_severity_score.nlargest(i).groupby(\"Patient ID\").mean()\n",
    "    mean_largest = pd.concat([mean_largest, covid], axis=1)\n",
    "    # n_largest.append(mean_largest.COVID19.corr(mean_largest.yolo_severity_score))\n",
    "    # Append spearman rank correlation\n",
    "    n_largest.append(spearmanr(mean_largest['yolo_severity_score'], mean_largest['COVID19'])[0])\n",
    "\n",
    "n_largest = pd.DataFrame(n_largest, index=range(1, max_length), columns=[\"correlation\"])\n",
    "\n",
    "# Find maxima of the n_largest correlations\n",
    "from scipy.signal import argrelextrema\n",
    "import numpy as np\n",
    "n=30\n",
    "n_largest['max'] = n_largest.iloc[argrelextrema(n_largest.correlation.values, np.greater_equal,\n",
    "                    order=n)[0]]['correlation']\n",
    "\n",
    "# Plot nlargest correlation with maxima\n",
    "sns.lineplot(data=n_largest, x=n_largest.index, y=\"correlation\").set(title=\"Correlation vs n largest severity scores\", xlabel=\"n largest severity scores\", ylabel=\"Correlation (Spearman Rank)\")\n",
    "sns.scatterplot(data=n_largest, x=n_largest.index, y=\"max\", color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the maxima\n",
    "n_largest = n_largest.dropna().reset_index().rename(columns={\"index\": \"n_largest\"}).drop(columns=[\"max\"])\n",
    "# Add the maxima to the aggregation strategies\n",
    "for idx, row in n_largest.iterrows():\n",
    "    n = row[\"n_largest\"].astype(int)\n",
    "    severity_nlargest_mean = patient_grp.yolo_severity_score.nlargest(n).groupby(\"Patient ID\").mean().rename(f\"yolo_severity_score_mean_largest_{n}\")\n",
    "    accumulation_df = pd.concat([accumulation_df, severity_nlargest_mean], axis=1)\n",
    "\n",
    "n_largest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictive performance of severity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_covEcho.statistics as logit_stats\n",
    "from importlib import reload\n",
    "reload(logit_stats)\n",
    "\n",
    "# Evaluate the logits of the YOLONet\n",
    "gt = severity_filtered[\"COVID19\"].values\n",
    "predictions = (severity_filtered[\"yolo_severity_score\"] >= 1).astype(int).values\n",
    "\n",
    "eval = logit_stats.evaluate_logits(gt, predictions, CLASSES=[\"No COVID\", \"COVID\"])\n",
    "eval = pd.concat([eval], keys=[\"None\"], names=['Accumulation'])\n",
    "eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values without patient level accumulation don't look very promising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next try to accumulate the severity scores by different means and check the patient-level performance.\n",
    "\n",
    "To do so we calculate get the optimal cut-off value for all aggregation strategies and evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to find optimal threshold values for all accumulation scores\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Taken from https://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "\n",
    "    Returns\n",
    "    -------     \n",
    "    list type, with optimal cutoff value\n",
    "        \n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "eval_acc = eval\n",
    "accumulation_columns = list(accumulation_df.columns[accumulation_df.columns.str.contains(\"yolo_severity_score\")])\n",
    "# Remove all columns containing numbers between 367 and 424\n",
    "exclude_numbers = [str(i) for i in range(367, 424)]\n",
    "accumulation_columns = [col for col in accumulation_columns if not any(num in col for num in exclude_numbers)]\n",
    "gt = accumulation_df[\"COVID19\"]\n",
    "for acc in accumulation_columns:\n",
    "    X = accumulation_df[acc]\n",
    "    y = gt\n",
    "    # Split into train and test to determine optimal cutoff on train set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    # Find optimal probability threshold\n",
    "    threshold = Find_Optimal_Cutoff(y_train, X_train)[0]\n",
    "    print(f\"Threshold for {acc}: {threshold}\")\n",
    "    # Find prediction to the dataframe applying threshold\n",
    "    predictions = X_test.map(lambda x: 1 if x > threshold else 0)\n",
    "    temp = logit_stats.evaluate_logits(y_test, predictions, CLASSES=[\"No COVID\", \"COVID\"])\n",
    "    temp = pd.concat([temp], keys=[acc], names=['Accumulation'])\n",
    "    eval_acc = pd.concat([eval_acc, temp])\n",
    "\n",
    "eval_acc.style.apply(highlight_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To latex formating .2f\n",
    "print(eval_acc[[\"accuracy\", \"recall\", \"specificity\", \"f1-score\"]].to_latex(float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This improves the results significantly. Its interesting to note that the std seems to be the most predictive variable of the simple aggregation schemas where as the max performs worst of all the accumulation strategies. This suggests that its (at least on our data without retraining the network) perhaps not the best strategy to assume that the \"worst\" frame suggests the state of the patient but that taking the mean or the sum is better. \n",
    "The best aggregation strategy over all is, however, to take the mean of the frames with the n largest severtiy scores. This supports the hypothesis that both looking at only one individual, most severe frame, as well as taking a vote of all the frames with equal rights is not the best method to go about determining a final diagnosis for a patient but that instead the vote of a subset of informative frames is the most promising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictive performance of manual severity labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the logits of the YOLONet\n",
    "gt = severity_filtered[\"COVID19\"].values\n",
    "predictions = (severity_filtered[\"manual_severity_score\"] >= 1).astype(int).values\n",
    "\n",
    "eval_manual = logit_stats.evaluate_logits(gt, predictions, CLASSES=[\"No COVID\", \"COVID\"])\n",
    "eval_manual"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictive performance of the manual severity scores are at chance level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bluepoint level severity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_filtered.yolo_severity_score.corr(severity_filtered.COVID19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bluepoints = severity_filtered.Bluepoint.unique()\n",
    "bluepoints = bluepoints[bluepoints != \"None\"]\n",
    "bluepoints.sort()\n",
    "bluepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seaborn plotting aesthetics as default\n",
    "sns.set(font_scale=1.5)\n",
    "#define plotting region \n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "for i, bp in enumerate(bluepoints):\n",
    "    # Filter the data\n",
    "    bp_df = severity_filtered[severity_filtered.Bluepoint == bp]\n",
    "    # Plot the data\n",
    "    print(f\"Bluepoint {bp} has {bp_df.shape[0]} frames\")\n",
    "    sns.boxplot(data=bp_df, x=\"COVID19\", y=\"yolo_severity_score\", ax=axes[i//3, i%3])\n",
    "    axes[i//3, i%3].set_title(f\"Bluepoint: {bp}\")\n",
    "    axes[i//3, i%3].set_xlabel(\"\")\n",
    "    axes[i//3, i%3].set_ylabel(\"covEcho Severity\")\n",
    "    axes[i//3, i%3].set_xticklabels([\"Negative\", \"COVID-19\"])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning L1 and R1 to the bilateral bluepoint \"1\", L2 and R2 to \"2\" and L3 and R3 to \"3\" for aggregated plotting\n",
    "severity_filtered[\"Bluepoint_bilateral\"] = severity_filtered[\"Bluepoint\"].apply(lambda x: x[1])\n",
    "\n",
    "# 3 subplots with scatter plot for each bluepoint BMI against std of severity score\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, bp in enumerate([\"1\", \"2\", \"3\"]):\n",
    "    # Filter the data\n",
    "    bp_df = severity_filtered[severity_filtered.Bluepoint_bilateral == bp]\n",
    "    # Plot the data\n",
    "    sns.boxplot(data=bp_df, x=\"COVID19\", y=\"yolo_severity_score\", ax=axes[i])\n",
    "    axes[i].set_title(f\"Bluepoint: {bp}\")\n",
    "    axes[i].set_xlabel(\"COVID19\")\n",
    "    axes[i].set_ylabel(\"covEcho severity score\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: How to statistically verify this observation? Mean distance between cov+ and -? Only one value (2 at max if both sides) per bp. How to compare them?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMI Test\n",
    "Test Ronalds hypothesis that the BMI influences ability to get good pictures and might in turn increase score variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clinical_vars = get_clinical_df()\n",
    "\n",
    "bmi_clinical = all_clinical_vars[[\"Video ID\", \"pat_bmi\"]]\n",
    "bmi_clinical = bmi_clinical.rename(columns={\"pat_bmi\": \"BMI\", \"Video ID\": \"Patient ID\"})\n",
    "bmi_hypothesis_df = yolo_detection_df[[\"Frame\", \"Patient ID\", \"Bluepoint\", \"yolo_severity_score\", \"manual_severity_score\", \"COVID19\"]].drop_duplicates().reset_index(drop=True)\n",
    "# Drop all frames with yolo_severity_score < 0\n",
    "bmi_hypothesis_df = bmi_hypothesis_df[bmi_hypothesis_df.yolo_severity_score >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by patient and bluepoint\n",
    "bmi_bluepoint_grouped = bmi_hypothesis_df.groupby([\"Patient ID\", \"Bluepoint\"]).agg({\"yolo_severity_score\": \"std\", \"manual_severity_score\": \"std\", \"COVID19\": \"first\"}).reset_index()\n",
    "bmi_patient_grouped = bmi_hypothesis_df.groupby([\"Patient ID\"]).agg({\"yolo_severity_score\": \"std\", \"manual_severity_score\": \"std\", \"COVID19\": \"first\"}).reset_index()\n",
    "# Rename columns to std\n",
    "bmi_bluepoint_grouped = bmi_bluepoint_grouped.rename(columns={\"yolo_severity_score\": \"yolo_severity_score_std\", \"manual_severity_score\": \"manual_severity_score_std\"})\n",
    "bmi_patient_grouped = bmi_patient_grouped.rename(columns={\"yolo_severity_score\": \"yolo_severity_score_std\", \"manual_severity_score\": \"manual_severity_score_std\"})\n",
    "# Merge with clinical data\n",
    "bmi_bluepoint_grouped = bmi_bluepoint_grouped.merge(bmi_clinical, on=\"Patient ID\")\n",
    "bmi_patient_grouped = bmi_patient_grouped.merge(bmi_clinical, on=\"Patient ID\")\n",
    "bmi_bluepoint_grouped.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test yolo_severity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for each bluepoint BMI against std of severity score\n",
    "#set seaborn plotting aesthetics as default\n",
    "sns.set()\n",
    "#define plotting region\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "for i, bp in enumerate(bluepoints):\n",
    "    # Filter the data\n",
    "    bp_df = bmi_bluepoint_grouped[bmi_bluepoint_grouped.Bluepoint == bp]\n",
    "    # Plot the data\n",
    "    sns.scatterplot(data=bp_df, x=\"BMI\", y=\"yolo_severity_score_std\", hue=\"COVID19\", ax=axes[i//3, i%3])\n",
    "    # Add regression line\n",
    "    sns.regplot(data=bp_df, x=\"BMI\", y=\"yolo_severity_score_std\", ax=axes[i//3, i%3], scatter=False)\n",
    "    axes[i//3, i%3].set_title(f\"Bluepoint: {bp}\")\n",
    "    axes[i//3, i%3].set_xlabel(\"BMI\")\n",
    "    axes[i//3, i%3].set_ylabel(\"Yolo severity score std\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Bluepoints\n",
    "# Assigning L1 and R1 to the bilateral bluepoint \"1\", L2 and R2 to \"2\" and L3 and R3 to \"3\" for aggregated plotting\n",
    "bmi_bluepoint_grouped[\"Bluepoint_bilateral\"] = bmi_bluepoint_grouped[\"Bluepoint\"].apply(lambda x: x[1])\n",
    "\n",
    "# 3 subplots with scatter plot for each bluepoint BMI against std of severity score\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, bp in enumerate([\"1\", \"2\", \"3\"]):\n",
    "    # Filter the data\n",
    "    bp_df = bmi_bluepoint_grouped[bmi_bluepoint_grouped.Bluepoint_bilateral == bp]\n",
    "    # Plot the data\n",
    "    sns.scatterplot(data=bp_df, x=\"BMI\", y=\"yolo_severity_score_std\", hue=\"COVID19\", ax=axes[i])\n",
    "    # Add regression line\n",
    "    sns.regplot(data=bp_df, x=\"BMI\", y=\"yolo_severity_score_std\", ax=axes[i], scatter=False)\n",
    "    # Calculate correlation\n",
    "    corr = bp_df.yolo_severity_score_std.corr(bp_df.BMI)\n",
    "    axes[i].set_title(f\"Bluepoint: {bp}. Correlation: {corr:.2f}\")\n",
    "    axes[i].set_xlabel(\"BMI\")\n",
    "    axes[i].set_ylabel(\"Yolo severity score std\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crucial plot leading us to reject the BMI hypothesis. The BMI does not seem to influence the variance of the severity scores, especially not for BP 2 and 3 which we would have expected to be the most affected by a higher BMI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(15, 5))\n",
    "\n",
    "# Plot the data\n",
    "sns.scatterplot(data=bmi_patient_grouped, x=\"BMI\", y=\"yolo_severity_score_std\", hue=\"COVID19\", ax=axes)\n",
    "# Add regression line\n",
    "sns.regplot(data=bmi_patient_grouped, x=\"BMI\", y=\"yolo_severity_score_std\", ax=axes, scatter=False)\n",
    "# Calculate correlation\n",
    "corr = bmi_patient_grouped.yolo_severity_score_std.corr(bmi_patient_grouped.BMI)\n",
    "\n",
    "axes.set_title(f\"Patient. Correlation: {corr:.2f}\")\n",
    "axes.set_xlabel(\"BMI\")\n",
    "axes.set_ylabel(\"Yolo severity score std\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test manual_severity_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For manual severity scores the Intra-Bluepoint variance does not make sense because there is only one score per video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(15, 5))\n",
    "\n",
    "# Plot the data\n",
    "sns.scatterplot(data=bmi_patient_grouped, x=\"BMI\", y=\"manual_severity_score_std\", hue=\"COVID19\", ax=axes)\n",
    "# Add regression line\n",
    "sns.regplot(data=bmi_patient_grouped, x=\"BMI\", y=\"manual_severity_score_std\", ax=axes, scatter=False)\n",
    "# Calculate correlation\n",
    "corr = bmi_patient_grouped.manual_severity_score_std.corr(bmi_patient_grouped.BMI)\n",
    "\n",
    "axes.set_title(f\"Patient. Correlation: {corr:.2f}\")\n",
    "axes.set_xlabel(\"BMI\")\n",
    "axes.set_ylabel(\"Manual severity score std\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different BMI approach. Correlate the error of the severity score with the BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clinical_vars = get_clinical_df()\n",
    "\n",
    "bmi_clinical = all_clinical_vars[[\"Video ID\", \"pat_bmi\"]]\n",
    "bmi_clinical = bmi_clinical.rename(columns={\"pat_bmi\": \"BMI\", \"Video ID\": \"Patient ID\"})\n",
    "bmi_hypothesis_df = yolo_detection_df[[\"Frame\", \"Patient ID\", \"Bluepoint\", \"yolo_severity_score\", \"manual_severity_score\", \"COVID19\"]].drop_duplicates().reset_index(drop=True)\n",
    "# Drop all frames with yolo_severity_score < 0\n",
    "bmi_hypothesis_df = bmi_hypothesis_df[bmi_hypothesis_df.yolo_severity_score >= 0]\n",
    "bmi_hypothesis_df = bmi_hypothesis_df.merge(bmi_clinical, on=\"Patient ID\")\n",
    "bmi_hypothesis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume severtiy_score > 0 is COVID19. Create prediction column\n",
    "bmi_hypothesis_df[\"yolo_prediction\"] = bmi_hypothesis_df[\"yolo_severity_score\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "bmi_hypothesis_df[\"manual_prediction\"] = bmi_hypothesis_df[\"manual_severity_score\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "# Create a column for the error between the prediction and the actual value\n",
    "bmi_hypothesis_df[\"yolo_prediction_err\"] = abs(bmi_hypothesis_df[\"yolo_prediction\"] - bmi_hypothesis_df[\"COVID19\"])\n",
    "bmi_hypothesis_df[\"manual_prediction_err\"] = abs(bmi_hypothesis_df[\"manual_prediction\"] - bmi_hypothesis_df[\"COVID19\"])\n",
    "\n",
    "bmi_bluepoint_grouped = bmi_hypothesis_df.groupby([\"Patient ID\", \"Bluepoint\"]).agg({\"yolo_prediction_err\": \"mean\", \"manual_prediction_err\": \"mean\", \"COVID19\": \"first\", \"BMI\": \"first\"}).reset_index()\n",
    "bmi_bluepoint_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for each bluepoint BMI against prediction error\n",
    "#define plotting region\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "for i, bp in enumerate(bluepoints):\n",
    "    # Filter the data\n",
    "    bp_df = bmi_bluepoint_grouped[bmi_bluepoint_grouped.Bluepoint == bp]\n",
    "    # Plot the data\n",
    "    sns.scatterplot(data=bp_df, x=\"BMI\", y=\"yolo_prediction_err\", hue=\"COVID19\", ax=axes[i//3, i%3])\n",
    "    # Add regression line\n",
    "    sns.regplot(data=bp_df, x=\"BMI\", y=\"yolo_prediction_err\", ax=axes[i//3, i%3], scatter=False)\n",
    "    axes[i//3, i%3].set_title(f\"Bluepoint: {bp}\")\n",
    "    axes[i//3, i%3].set_xlabel(\"BMI\")\n",
    "    axes[i//3, i%3].set_ylabel(\"covEcho prediction error\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "# Aggregate Bluepoints\n",
    "# Assigning L1 and R1 to the bilateral bluepoint \"1\", L2 and R2 to \"2\" and L3 and R3 to \"3\" for aggregated plotting\n",
    "bmi_bluepoint_grouped[\"Bluepoint_bilateral\"] = bmi_bluepoint_grouped[\"Bluepoint\"].apply(lambda x: x[1])\n",
    "# Drop rows with nan values\n",
    "bmi_bluepoint_grouped = bmi_bluepoint_grouped.dropna()\n",
    "\n",
    "# 3 subplots with scatter plot for each bluepoint BMI against prediction error\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "for i, bp in enumerate([\"1\", \"2\", \"3\"]):\n",
    "    # Filter the data\n",
    "    bp_df = bmi_bluepoint_grouped[bmi_bluepoint_grouped.Bluepoint_bilateral == bp]\n",
    "    # Plot the data\n",
    "    sns.scatterplot(data=bp_df, x=\"BMI\", y=\"yolo_prediction_err\", hue=\"COVID19\", ax=axes[i])\n",
    "    # Add regression line\n",
    "    sns.regplot(data=bp_df, x=\"BMI\", y=\"yolo_prediction_err\", ax=axes[i], scatter=False)\n",
    "    # Calculate pearson correlation\n",
    "    corr, p = stats.pearsonr(bp_df.BMI, bp_df.yolo_prediction_err)\n",
    "    axes[i].set_title(f\"BP: {bp}. Corr: {corr:.2f}, p: {p:.2f}\")\n",
    "    axes[i].set_xlabel(\"BMI\")\n",
    "    #axes[i].set_ylabel(\"covEcho prediction error\")\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"covEcho prediction error\")\n",
    "    else:\n",
    "        axes[i].set_ylabel(\"\")\n",
    "    # Fix legend top right corner\n",
    "    axes[i].legend(loc='upper right', fontsize='small', title_fontsize='small')\n",
    "    # Set legend titel to \"COVID19\"\n",
    "    axes[i].get_legend().set_title(\"COVID19\")\n",
    "    # Reduce y tick font size\n",
    "    #axes[i].tick_params(axis='y', labelsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Patient ID and Bluepoint and get the mean error and the first value of severity score\n",
    "bmi_hypothesis_df_patient = bmi_hypothesis_df.groupby([\"Patient ID\", \"Bluepoint\"]).agg({\"yolo_prediction_err\": \"mean\", \"manual_prediction_err\": \"mean\", \"yolo_severity_score\": \"first\", \"manual_severity_score\": \"first\", \"COVID19\": \"first\", \"BMI\": \"first\"}).reset_index()\n",
    "\n",
    "# Plot yolo_prediction_err against BMI\n",
    "fig, axes = plt.subplots(1, 1, figsize=(15, 5))\n",
    "\n",
    "# Plot the data\n",
    "sns.scatterplot(data=bmi_hypothesis_df_patient, x=\"BMI\", y=\"yolo_prediction_err\", hue=\"COVID19\", ax=axes)\n",
    "# Add regression line\n",
    "sns.regplot(data=bmi_hypothesis_df_patient, x=\"BMI\", y=\"yolo_prediction_err\", ax=axes, scatter=False)\n",
    "# Calculate correlation\n",
    "corr = bmi_hypothesis_df_patient.yolo_prediction_err.corr(bmi_hypothesis_df_patient.BMI)\n",
    "axes.set_title(f\"covEcho prediction error vs BMI. Correlation: {corr:.2f}\")\n",
    "axes.set_xlabel(\"BMI\")\n",
    "axes.set_ylabel(\"covEcho prediction error\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bp in bluepoints:\n",
    "    if bp == \"None\":\n",
    "        continue\n",
    "    corr_cov = severity_filtered[severity_filtered.Bluepoint == bp].yolo_severity_score.corr(severity_filtered[severity_filtered.Bluepoint == bp].COVID19)\n",
    "    # Spearman correlation\n",
    "    corr_spearman = severity_filtered[severity_filtered.Bluepoint == bp].yolo_severity_score.corr(severity_filtered[severity_filtered.Bluepoint == bp].COVID19, method=\"spearman\")\n",
    "    print(f\"Bluepoint: {bp}\\tCorr: {corr_spearman:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very interesting plots of the Bluepoints. It seems like L1 and R1 are significantly more related to COVID than the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_left = severity_filtered[severity_filtered.Bluepoint.isin([\"L1\", \"L2\", \"L3\"])].yolo_severity_score\n",
    "bp_right = severity_filtered[severity_filtered.Bluepoint.isin([\"R1\", \"R2\", \"R3\"])].yolo_severity_score\n",
    "\n",
    "bp_1 = severity_filtered[severity_filtered.Bluepoint.isin([\"L1\", \"R1\"])].yolo_severity_score\n",
    "bp_2 = severity_filtered[severity_filtered.Bluepoint.isin([\"L2\", \"R2\"])].yolo_severity_score\n",
    "bp_3 = severity_filtered[severity_filtered.Bluepoint.isin([\"L3\", \"R3\"])].yolo_severity_score\n",
    "\n",
    "p_values = []\n",
    "\n",
    "# Mann-Whitney U-Test\n",
    "stat, p_value = mannwhitneyu(bp_left, bp_right)\n",
    "p_values.append(p_value)\n",
    "print(\"Bluepoint left vs right\")\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "print(f\"Mean severity left: {bp_left.mean():.4f}\")\n",
    "print(f\"Mean severity right: {bp_right.mean():.4f}\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Bluepoint 1 vs 2 vs 3\")\n",
    "print(\"1 vs 2\")\n",
    "stat, p_value = mannwhitneyu(bp_1, bp_2)\n",
    "p_values.append(p_value)\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "print(\"2 vs 3\")\n",
    "stat, p_value = mannwhitneyu(bp_2, bp_3)\n",
    "p_values.append(p_value)\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "print(\"1 vs 3\")\n",
    "stat, p_value = mannwhitneyu(bp_1, bp_3)\n",
    "p_values.append(p_value)\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "\n",
    "print(\"\\nMeans:\")\n",
    "print(f\"Mean severity 1: {bp_1.mean():.4f}\")\n",
    "print(f\"Mean severity 2: {bp_2.mean():.4f}\")\n",
    "print(f\"Mean severity 3: {bp_3.mean():.4f}\")\n",
    "\n",
    "\n",
    "# Using bonferonni correction for multiple comparisons\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "p_adjusted = multipletests(p_values, method='bonferroni')\n",
    "\n",
    "print(\"Bonferroni corrected p-values:\")\n",
    "\n",
    "test_distributions = [\"L vs R\", \"1 vs 2\", \"2 vs 3\", \"1 vs 3\"]\n",
    "# Print green if p-value is significant otherwise red\n",
    "for i, p in enumerate(p_adjusted[1]):\n",
    "    if p < 0.05:\n",
    "        print(f\"\\033[92m{test_distributions[i]}: {p:.4f}\\033[0m\")\n",
    "    else:\n",
    "        print(f\"\\033[91m{test_distributions[i]}: {p:.4f}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The density plot shows the same picture. A lot better separation along the severiy score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by this result check the predictive performance of the severity score per bluepoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_covEcho.statistics as logit_stats\n",
    "from importlib import reload\n",
    "reload(logit_stats)\n",
    "\n",
    "# Evaluate the logits of the YOLONet for all bluepoints\n",
    "gt = severity_filtered[\"COVID19\"].values\n",
    "predictions = (severity_filtered[\"yolo_severity_score\"] >= 1).astype(int).values\n",
    "\n",
    "eval = logit_stats.evaluate_logits(gt, predictions, CLASSES=[\"No COVID\", \"COVID\"])\n",
    "eval = pd.concat([eval], keys=[\"All\"], names=['Bluepoint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_bp = eval\n",
    "for bp in bluepoints:\n",
    "    if bp == \"None\": continue\n",
    "    bp_df = severity_filtered[severity_filtered.Bluepoint == bp]\n",
    "    gt = bp_df[\"COVID19\"].values\n",
    "    predictions = (bp_df[\"yolo_severity_score\"] >= 1).astype(int).values\n",
    "    temp = logit_stats.evaluate_logits(gt, predictions, CLASSES=[\"No COVID\", \"COVID\"])\n",
    "    temp = pd.concat([temp], keys=[bp], names=['Bluepoint'])\n",
    "    eval_bp = pd.concat([eval_bp, temp])\n",
    "\n",
    "def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['color: green' if cell else '' for cell in is_max]\n",
    "\n",
    "eval_bp.style.background_gradient().apply(highlight_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latex = eval_bp.drop(columns=[\"specificity\", \"precision\", \"recall\", \"accuracy\", \"f1-score\", \"mcc\"])\n",
    "# print(latex.reset_index().drop(columns=[\"level_1\"]).drop_duplicates().rename(columns={\"balanced\": \"Balanced Accuracy\"}).to_latex(index=False, float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 seems to be over all the best performing bp. R1 is similarly prominent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blue point analysis on manual severity labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_filtered_manual = severity_filtered[[\"Patient ID\", \"COVID19\", \"manual_severity_score\", \"Bluepoint\"]]\n",
    "severity_filtered_manual = severity_filtered_manual.dropna()\n",
    "severity_filtered_manual = severity_filtered_manual.drop_duplicates()\n",
    "severity_filtered_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seaborn plotting aesthetics as default\n",
    "sns.set()\n",
    "#define plotting region \n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "for i, bp in enumerate(bluepoints):\n",
    "    # Filter the data\n",
    "    bp_df = severity_filtered_manual[severity_filtered_manual.Bluepoint == bp]\n",
    "    # Plot the data\n",
    "    print(f\"Bluepoint {bp} has {bp_df.shape[0]} values\")\n",
    "    sns.boxplot(data=bp_df, x=\"COVID19\", y=\"manual_severity_score\", ax=axes[i//3, i%3])\n",
    "    axes[i//3, i%3].set_title(f\"Bluepoint: {bp}\")\n",
    "    axes[i//3, i%3].set_xlabel(\"Yolo severity score\")\n",
    "    axes[i//3, i%3].set_ylabel(\"COVID19\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning L1 and R1 to the bilateral bluepoint \"1\", L2 and R2 to \"2\" and L3 and R3 to \"3\" for aggregated plotting\n",
    "severity_filtered_manual[\"Bluepoint_bilateral\"] = severity_filtered_manual[\"Bluepoint\"].apply(lambda x: x[1])\n",
    "\n",
    "# 3 subplots with scatter plot for each bluepoint BMI against std of severity score\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, bp in enumerate([\"1\", \"2\", \"3\"]):\n",
    "    # Filter the data\n",
    "    bp_df = severity_filtered_manual[severity_filtered_manual.Bluepoint_bilateral == bp]\n",
    "    # Plot the data\n",
    "    sns.boxplot(data=bp_df, x=\"COVID19\", y=\"manual_severity_score\", ax=axes[i])\n",
    "    axes[i].set_title(f\"Bluepoint: {bp}\")\n",
    "    axes[i].set_xlabel(\"COVID19\")\n",
    "    axes[i].set_ylabel(\"Manual severity score\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_left = severity_filtered_manual[severity_filtered_manual.Bluepoint.isin([\"L1\", \"L2\", \"L3\"])].manual_severity_score\n",
    "bp_right = severity_filtered_manual[severity_filtered_manual.Bluepoint.isin([\"R1\", \"R2\", \"R3\"])].manual_severity_score\n",
    "\n",
    "bp_1 = severity_filtered_manual[severity_filtered_manual.Bluepoint.isin([\"L1\", \"R1\"])].manual_severity_score\n",
    "bp_2 = severity_filtered_manual[severity_filtered_manual.Bluepoint.isin([\"L2\", \"R2\"])].manual_severity_score\n",
    "bp_3 = severity_filtered_manual[severity_filtered_manual.Bluepoint.isin([\"L3\", \"R3\"])].manual_severity_score\n",
    "\n",
    "p_values = []\n",
    "\n",
    "# Mann-Whitney U-Test\n",
    "stat, p_value = mannwhitneyu(bp_left, bp_right)\n",
    "p_values.append(p_value)\n",
    "print(\"Bluepoint left vs right\")\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "print(f\"Mean severity left: {bp_left.mean():.4f}\")\n",
    "print(f\"Mean severity right: {bp_right.mean():.4f}\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Bluepoint 1 vs 2 vs 3\")\n",
    "print(\"1 vs 2\")\n",
    "stat, p_value = mannwhitneyu(bp_1, bp_2)\n",
    "p_values.append(p_value)\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "print(\"2 vs 3\")\n",
    "stat, p_value = mannwhitneyu(bp_2, bp_3)\n",
    "p_values.append(p_value)\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "print(\"1 vs 3\")\n",
    "stat, p_value = mannwhitneyu(bp_1, bp_3)\n",
    "p_values.append(p_value)\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "\n",
    "print(\"\\nMeans:\")\n",
    "print(f\"Mean severity 1: {bp_1.mean():.4f}\")\n",
    "print(f\"Mean severity 2: {bp_2.mean():.4f}\")\n",
    "print(f\"Mean severity 3: {bp_3.mean():.4f}\")\n",
    "\n",
    "\n",
    "# Using bonferonni correction for multiple comparisons\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "p_adjusted = multipletests(p_values, method='bonferroni')\n",
    "\n",
    "print(\"Bonferroni corrected p-values:\")\n",
    "\n",
    "test_distributions = [\"L vs R\", \"1 vs 2\", \"2 vs 3\", \"1 vs 3\"]\n",
    "# Print green if p-value is significant otherwise red\n",
    "for i, p in enumerate(p_adjusted[1]):\n",
    "    if p < 0.05:\n",
    "        print(f\"\\033[92m{test_distributions[i]}: {p:.4f}\\033[0m\")\n",
    "    else:\n",
    "        print(f\"\\033[91m{test_distributions[i]}: {p:.4f}\\033[0m\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class area analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add class count, weightes class count and weighted class area by confidence\n",
    "yolo_detection_df[\"area_weighted\"] = yolo_detection_df[\"area\"] * yolo_detection_df[\"confidence\"]\n",
    "grp = yolo_detection_df.groupby([\"video_name\", \"class\"])\n",
    "video_lvl = grp.agg({\"class\": \"count\", \"confidence\": \"sum\", \"area\": \"sum\", \"area_weighted\": \"sum\"})\n",
    "video_lvl = video_lvl.rename(columns={\"class\": \"class_count\", \"confidence\": \"class_count_conf_weighted\", \"area\": \"area\", \"area_weighted\": \"area_conf_weighted\"}).reset_index()\n",
    "\n",
    "# Add frame count\n",
    "frame_count_per_video = yolo_detection_df[[\"video_name\", \"Frame\"]].drop_duplicates().groupby([\"video_name\"]).count().reset_index().rename(columns={\"Frame\": \"Frame_count\"})\n",
    "video_lvl = pd.merge(video_lvl, frame_count_per_video, on=\"video_name\")\n",
    "\n",
    "\n",
    "# Devide by frame count to account for different video lengths\n",
    "video_lvl[\"area\"] = video_lvl[\"area\"] / video_lvl[\"Frame_count\"]\n",
    "video_lvl[\"area_conf_weighted\"] = video_lvl[\"area_conf_weighted\"] / video_lvl[\"Frame_count\"]\n",
    "video_lvl[\"class_count\"] = video_lvl[\"class_count\"] / video_lvl[\"Frame_count\"]\n",
    "video_lvl[\"class_count_conf_weighted\"] = video_lvl[\"class_count_conf_weighted\"] / video_lvl[\"Frame_count\"]\n",
    "\n",
    "# Add classes with 0 area\n",
    "possible_classes = list(range(len(class_names)))\n",
    "video_names = yolo_detection_df.video_name.unique().tolist()\n",
    "from itertools import product\n",
    "idx_df =  pd.DataFrame(list(product(possible_classes,video_names))).rename(columns={0:'class',1:'video_name'})\n",
    "\n",
    "video_lvl = pd.merge(idx_df, video_lvl, on=[\"video_name\", \"class\"], how=\"left\").fillna(0).sort_values(by=[\"video_name\", \"class\"])\n",
    "\n",
    "video_lvl[\"class_name\"] = video_lvl[\"class\"].map(lambda x: class_names[x])\n",
    "\n",
    "patient_data = yolo_detection_df.groupby([\"Patient ID\", \"video_name\"]).agg({\"COVID19\": \"first\",\"Bluepoint\": \"first\", \"yolo_severity_score\": \"mean\", \"manual_severity_score\" : \"first\"}).reset_index()\n",
    "video_level = pd.merge(video_lvl, patient_data, on=\"video_name\").sort_values(by=[\"Patient ID\", \"Bluepoint\", \"class\"]).reset_index(drop=True)\n",
    "# Reorder columns\n",
    "video_level = video_level[[\"Patient ID\", \"COVID19\", \"Bluepoint\", \"video_name\", \"yolo_severity_score\", \"manual_severity_score\", \"class\", \"class_name\", \"class_count\", \"class_count_conf_weighted\", \"area\", \"area_conf_weighted\"]]\n",
    "video_level.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding information whether class is pathological or not. For now I assume class 0, 2, 3 and 4 are pathological\n",
    "# Class names: ['0: Airbronchograms', '1: Alines', '2: Blines', '3: Bpatch', '4: Consolidations', '5: Pleura', '6: Rib', '7: Shadow']\n",
    "pathological_classes = [0, 2, 3, 4]\n",
    "non_pathological_classes = [1, 5, 6, 7]\n",
    "pathological_class_names = [class_names[x] for x in pathological_classes]\n",
    "non_pathological_class_names = [class_names[x] for x in non_pathological_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathological_classes_df = video_level[video_level[\"class\"].isin(pathological_classes)]\n",
    "\n",
    "# perform statistical tests\n",
    "print(\"Class count\")\n",
    "print(\"COVID19 vs non-COVID19\")\n",
    "stat, p_value = mannwhitneyu(pathological_classes_df[pathological_classes_df[\"COVID19\"] == 1][\"class_count\"], pathological_classes_df[pathological_classes_df[\"COVID19\"] == 0][\"class_count\"])\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "# Print green if p-value is significant otherwise red\n",
    "if p_value < 0.05:\n",
    "    print(\"\\033[92mSignificant difference\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[91mNo significant difference\\033[0m\")\n",
    "print(\"Area\")\n",
    "print(\"COVID19 vs non-COVID19 \")\n",
    "stat, p_value = mannwhitneyu(pathological_classes_df[pathological_classes_df[\"COVID19\"] == 1][\"area\"], pathological_classes_df[pathological_classes_df[\"COVID19\"] == 0][\"area\"])\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "# Print green if p-value is significant otherwise red\n",
    "if p_value < 0.05:\n",
    "    print(\"\\033[92mSignificant difference\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[91mNo significant difference\\033[0m\")\n",
    "\n",
    "print(\"Means:\")\n",
    "print(f\"Mean class count COVID19: {pathological_classes_df[pathological_classes_df['COVID19'] == 1]['class_count'].mean():.4f}\")\n",
    "print(f\"Mean class count non-COVID19: {pathological_classes_df[pathological_classes_df['COVID19'] == 0]['class_count'].mean():.4f}\")\n",
    "print(f\"Mean area COVID19: {pathological_classes_df[pathological_classes_df['COVID19'] == 1]['area'].mean():.4f}\")\n",
    "print(f\"Mean area non-COVID19: {pathological_classes_df[pathological_classes_df['COVID19'] == 0]['area'].mean():.4f}\")\n",
    "\n",
    "#set seaborn plotting aesthetics as default\n",
    "sns.set()\n",
    "#define plotting region \n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "#plot the data\n",
    "sns.violinplot(data=pathological_classes_df, x=\"COVID19\", y=\"class_count\", ax=axes[0])\n",
    "sns.violinplot(data=pathological_classes_df, x=\"COVID19\", y=\"area\", ax=axes[1])\n",
    "\n",
    "#set titles\n",
    "axes[0].set_title(\"Class count\")\n",
    "axes[1].set_title(\"Class area\")\n",
    "#set y axis labels\n",
    "axes[0].set_ylabel(\"Class count\")\n",
    "axes[1].set_ylabel(\"Class area\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To beginn we try 4 different methods to aggregate the classes over time. \n",
    "1. Simple class count per video divided by the number of frames (avrg number of classes per frame).\n",
    "2. The class count weighted by the networks confidence divided by n frames.\n",
    "3. The area of the detected classes summed up divided by n frames. Testing the hypothesis that the affected area has a predictive power for covid.\n",
    "4. The area weighted by the networks confidence /n_Frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different standard models using all class areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import ml_pipeline\n",
    "importlib.reload(ml_pipeline)\n",
    "from ml_pipeline import ModelEvaluation\n",
    "\n",
    "\n",
    "Classifier = ModelEvaluation(mode=\"classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train models on accumulated area of all detected classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on all aggregation methods\n",
    "agg_eval = pd.DataFrame()\n",
    "agg_scores = pd.DataFrame()\n",
    "agg_methods = [\"area\", \"area_conf_weighted\", \"class_count\", \"class_count_conf_weighted\"]\n",
    "for agg_method in agg_methods:\n",
    "    # Pivot table for regression\n",
    "    class_area_per_video_pivot = video_level.pivot(index=\"video_name\", columns=\"class_name\", values=agg_method).reset_index()\n",
    "    class_area_per_video_pivot = pd.merge(class_area_per_video_pivot, video_level[[\"video_name\", \"COVID19\", \"Bluepoint\", \"Patient ID\"]], on=\"video_name\")\n",
    "    class_area_per_video_pivot = class_area_per_video_pivot.drop_duplicates().reset_index(drop=True)\n",
    "    # Shuffle\n",
    "    class_area_per_video_pivot = class_area_per_video_pivot.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "    # Split into X and y\n",
    "    X = class_area_per_video_pivot[class_names]\n",
    "    y = class_area_per_video_pivot[\"COVID19\"]\n",
    "    groups = class_area_per_video_pivot[\"Patient ID\"]\n",
    "\n",
    "    # Train models\n",
    "    scores, scores_mean = Classifier.train_models(X, y, groups=groups, plot=False)\n",
    "\n",
    "    # Add index level to df for aggregation\n",
    "    scores = pd.concat([scores], keys=[agg_method], names=['Aggregation method'])\n",
    "    scores_mean = pd.concat([scores_mean], keys=[agg_method], names=['Aggregation method'])\n",
    "    \n",
    "    # Add to dataframe\n",
    "    agg_scores = pd.concat([agg_scores, scores])\n",
    "    agg_eval = pd.concat([agg_eval, scores_mean])\n",
    "\n",
    "agg_eval.style.apply(highlight_max).format(\"{:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To latex formatig .format(\"{:.2f}\")\n",
    "print(agg_eval.style.apply(highlight_max).format(\"{:.2f}\").to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models performance of 57% accuracy is not great but comparable to our first approaches of training the NN. It can't compete with the best values of the severity analysis so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the best model (class_count) and save model predictions\n",
    "# Pivot table for regression\n",
    "class_area_per_video_pivot = video_level.pivot(index=\"video_name\", columns=\"class_name\", values=\"class_count\").reset_index()\n",
    "class_area_per_video_pivot = pd.merge(class_area_per_video_pivot, video_level[[\"video_name\", \"COVID19\", \"Bluepoint\", \"Patient ID\"]], on=\"video_name\")\n",
    "class_area_per_video_pivot = class_area_per_video_pivot.drop_duplicates().reset_index(drop=True)\n",
    "# Shuffle\n",
    "class_area_per_video_pivot = class_area_per_video_pivot.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "# Split into X and y\n",
    "X = class_area_per_video_pivot[class_names]\n",
    "y = class_area_per_video_pivot[\"COVID19\"]\n",
    "groups = class_area_per_video_pivot[\"Patient ID\"]\n",
    "\n",
    "# Train models\n",
    "scores, scores_mean, predictions = Classifier.train_models(X, y, groups=groups, plot=False, return_model_predictions=class_area_per_video_pivot)\n",
    "\n",
    "# Save predictions\n",
    "predictions.to_csv(\"predictions_covEcho_class_count_video_lvl_COVID.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statannot import add_stat_annotation\n",
    "from itertools import product\n",
    "\n",
    "pairs = [('area', 'class_count'),\n",
    "        ('area_conf_weighted', 'area'),\n",
    "        ('class_count_conf_weighted', 'class_count')]\n",
    "\n",
    "scores_all_classes = agg_scores.reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = sns.boxplot(data=scores_all_classes, x=\"Aggregation method\", y=\"test_accuracy\", palette=\"Set3\")\n",
    "add_stat_annotation(ax, data=scores_all_classes, x=\"Aggregation method\", y=\"test_accuracy\",\n",
    "                    box_pairs=pairs,\n",
    "                    test='Mann-Whitney', text_format='star', loc='outside', verbose=2)\n",
    "plt.title(\"Accuracy of different aggregation methods for all classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the different aggregation strategies show that incorporating the networks confidence does not significantly improve the network.\n",
    "We can also see that the class count is not significantly more predicitve than the summed up area. This suggests to reject the hyptothesis that the area for this network has a significant informative value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if restricting to pathological classes makes a change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding information whether class is pathological or not. For now I assume class 0, 2, 3 and 4 are pathological\n",
    "# Class names: ['0: Airbronchograms', '1: Alines', '2: Blines', '3: Bpatch', '4: Consolidations', '5: Pleura', '6: Rib', '7: Shadow']\n",
    "pathological_classes = [0, 2, 3, 4]\n",
    "non_pathological_classes = [1, 5, 6, 7]\n",
    "pathological_class_names = [class_names[x] for x in pathological_classes]\n",
    "non_pathological_class_names = [class_names[x] for x in non_pathological_classes]\n",
    "video_level[\"pathological_class\"] = video_level[\"class\"].apply(lambda x: 1 if x in pathological_classes else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train models on aggregated class (area) of all pathological classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on all aggregation methods\n",
    "agg_eval = pd.DataFrame()\n",
    "agg_scores = pd.DataFrame()\n",
    "agg_methods = [\"area\", \"area_conf_weighted\", \"class_count\", \"class_count_conf_weighted\"]\n",
    "for agg_method in agg_methods:\n",
    "    # Pivot table for regression\n",
    "    class_area_per_video_pivot = video_level.pivot(index=\"video_name\", columns=\"class_name\", values=agg_method).reset_index()\n",
    "    class_area_per_video_pivot = pd.merge(class_area_per_video_pivot, video_level[[\"video_name\", \"COVID19\", \"Bluepoint\", \"Patient ID\"]], on=\"video_name\")\n",
    "    class_area_per_video_pivot = class_area_per_video_pivot.drop_duplicates().reset_index(drop=True)\n",
    "    # Shuffle\n",
    "    class_area_per_video_pivot = class_area_per_video_pivot.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "    # Split into X and y\n",
    "    X = class_area_per_video_pivot[pathological_class_names]\n",
    "    y = class_area_per_video_pivot[\"COVID19\"]\n",
    "    groups = class_area_per_video_pivot[\"Patient ID\"]\n",
    "\n",
    "    # Train models\n",
    "    scores, scores_mean = Classifier.train_models(X, y, groups=groups, plot=False)\n",
    "\n",
    "    # Add index level to df for aggregation\n",
    "    scores = pd.concat([scores], keys=[agg_method], names=['Aggregation method'])\n",
    "    scores_mean = pd.concat([scores_mean], keys=[agg_method], names=['Aggregation method'])\n",
    "    \n",
    "    # Add to dataframe\n",
    "    agg_scores = pd.concat([agg_scores, scores])\n",
    "    agg_eval = pd.concat([agg_eval, scores_mean])\n",
    "\n",
    "agg_eval.style.apply(highlight_max).format(\"{:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statannot import add_stat_annotation\n",
    "from itertools import product\n",
    "\n",
    "pairs = [('area', 'class_count'),\n",
    "        ('area_conf_weighted', 'area'),\n",
    "        ('class_count_conf_weighted', 'class_count'),\n",
    "        ]\n",
    "\n",
    "scores_pathological_classes = agg_scores.reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "ax = sns.boxplot(data=scores_pathological_classes, x=\"Aggregation method\", y=\"test_accuracy\", palette=\"Set3\")\n",
    "add_stat_annotation(ax, data=scores_pathological_classes, x=\"Aggregation method\", y=\"test_accuracy\",\n",
    "                    box_pairs=pairs,\n",
    "                    test='Mann-Whitney', text_format='star', loc='outside', verbose=0)\n",
    "plt.title(\"Accuracy of different aggregation methods\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When restricting to the pathological classes there is no significant difference between either area or class_count and no significant difference when weighting by the networks confidence.\n",
    "\n",
    "The mean of the class count is the highest which is why we will proceed using the class count as primary aggregation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mann-Whitney U-Test\n",
    "x0 = scores_all_classes[\"test_accuracy\"]\n",
    "x1 = scores_pathological_classes[\"test_accuracy\"]\n",
    "stat, p_value = mannwhitneyu(x0, x1)\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "print(f\"Mean accuracy all classes: {x0.mean():.4f}\")\n",
    "print(f\"Mean accuracy pathological classes: {x1.mean():.4f}\")\n",
    "\n",
    "# Print green if p-value is significant otherwise red\n",
    "if p_value < 0.05:\n",
    "    print(\"\\033[92mSignificant difference\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[91mNo significant difference\\033[0m\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on all trained models and all used aggregation strategies shows that restricting the model input to the pathological classes is not significantly better $(p > 0.05)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to some extend not suprising since the information about the pathological classes is also contained in the full set of class names. Instead we check if restricting the model to only non-pathologocal classes decreases performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on all aggregation methods\n",
    "agg_eval = pd.DataFrame()\n",
    "agg_scores = pd.DataFrame()\n",
    "agg_methods = [\"area\", \"area_conf_weighted\", \"class_count\", \"class_count_conf_weighted\"]\n",
    "for agg_method in agg_methods:\n",
    "    # Pivot table for regression\n",
    "    class_area_per_video_pivot = video_level.pivot(index=\"video_name\", columns=\"class_name\", values=agg_method).reset_index()\n",
    "    class_area_per_video_pivot = pd.merge(class_area_per_video_pivot, video_level[[\"video_name\", \"COVID19\", \"Bluepoint\", \"Patient ID\"]], on=\"video_name\")\n",
    "    class_area_per_video_pivot = class_area_per_video_pivot.drop_duplicates().reset_index(drop=True)\n",
    "    # Shuffle\n",
    "    class_area_per_video_pivot = class_area_per_video_pivot.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "    # Split into X and y\n",
    "    X = class_area_per_video_pivot[non_pathological_class_names]\n",
    "    y = class_area_per_video_pivot[\"COVID19\"]\n",
    "    groups = class_area_per_video_pivot[\"Patient ID\"]\n",
    "\n",
    "    # Train models\n",
    "    scores, scores_mean = Classifier.train_models(X, y, groups=groups, plot=False)\n",
    "\n",
    "    # Add index level to df for aggregation\n",
    "    scores = pd.concat([scores], keys=[agg_method], names=['Aggregation method'])\n",
    "    scores_mean = pd.concat([scores_mean], keys=[agg_method], names=['Aggregation method'])\n",
    "    \n",
    "    # Add to dataframe\n",
    "    agg_scores = pd.concat([agg_scores, scores])\n",
    "    agg_eval = pd.concat([agg_eval, scores_mean])\n",
    "\n",
    "agg_eval.style.apply(highlight_max).format(\"{:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statannot import add_stat_annotation\n",
    "from itertools import product\n",
    "\n",
    "pairs = [('area', 'class_count'),\n",
    "        ('area_conf_weighted', 'area'),\n",
    "        ('class_count_conf_weighted', 'class_count'),\n",
    "        ]\n",
    "\n",
    "scores_non_pathological_classes = agg_scores.reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "ax = sns.boxplot(data=scores_non_pathological_classes, x=\"Aggregation method\", y=\"test_accuracy\", palette=\"Set3\")\n",
    "add_stat_annotation(ax, data=scores_non_pathological_classes, x=\"Aggregation method\", y=\"test_accuracy\",\n",
    "                    box_pairs=pairs,\n",
    "                    test='Mann-Whitney', text_format='star', loc='outside', verbose=0)\n",
    "plt.title(\"Accuracy of different aggregation methods\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mann-Whitney U-Test\n",
    "x0 = scores_all_classes[\"test_accuracy\"]\n",
    "x1 = scores_non_pathological_classes[\"test_accuracy\"]\n",
    "stat, p_value = mannwhitneyu(x0, x1)\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "print(f\"Mean accuracy all classes: {x0.mean():.4f}\")\n",
    "print(f\"Mean accuracy non pathological classes: {x1.mean():.4f}\")\n",
    "\n",
    "# Print green if p-value is significant otherwise red\n",
    "if p_value < 0.05:\n",
    "    print(\"\\033[92mSignificant difference\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[91mNo significant difference\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all classes vs using only non-pathological classes for training makes a significant difference across all models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient level area analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add class count, weightes class count and weighted class area by confidence\n",
    "yolo_detection_df[\"area_weighted\"] = yolo_detection_df[\"area\"] * yolo_detection_df[\"confidence\"]\n",
    "grp = yolo_detection_df.groupby([\"Patient ID\", \"class\"])\n",
    "patient_lvl = grp.agg({\"class\": \"count\", \"confidence\": \"sum\", \"area\": \"sum\", \"area_weighted\": \"sum\"})\n",
    "patient_lvl = patient_lvl.rename(columns={\"class\": \"class_count\", \"confidence\": \"class_count_conf_weighted\", \"area\": \"area\", \"area_weighted\": \"area_conf_weighted\"}).reset_index()\n",
    "\n",
    "# Add frame count\n",
    "frame_count_per_patient = yolo_detection_df[[\"Patient ID\", \"Bluepoint\", \"Frame\"]].drop_duplicates().groupby([\"Patient ID\"]).count().reset_index().rename(columns={\"Frame\": \"Frame_count\"}).drop(columns=[\"Bluepoint\"])\n",
    "patient_lvl = pd.merge(patient_lvl, frame_count_per_patient, on=\"Patient ID\")\n",
    "\n",
    "\n",
    "# Devide by frame count to get the average area per frame\n",
    "patient_lvl[\"area\"] = patient_lvl[\"area\"] / patient_lvl[\"Frame_count\"]\n",
    "patient_lvl[\"area_conf_weighted\"] = patient_lvl[\"area_conf_weighted\"] / patient_lvl[\"Frame_count\"]\n",
    "patient_lvl[\"class_count\"] = patient_lvl[\"class_count\"] / patient_lvl[\"Frame_count\"]\n",
    "patient_lvl[\"class_count_conf_weighted\"] = patient_lvl[\"class_count_conf_weighted\"] / patient_lvl[\"Frame_count\"]\n",
    "\n",
    "\n",
    "# Add classes with 0 area\n",
    "possible_classes = list(range(len(class_names)))\n",
    "patient_names = yolo_detection_df[\"Patient ID\"].unique().tolist()\n",
    "from itertools import product\n",
    "idx_df =  pd.DataFrame(list(product(possible_classes, patient_names))).rename(columns={0:'class',1:'Patient ID'})\n",
    "\n",
    "patient_lvl = pd.merge(idx_df, patient_lvl, on=[\"Patient ID\", \"class\"], how=\"left\").fillna(0).sort_values(by=[\"Patient ID\", \"class\"])\n",
    "\n",
    "patient_lvl[\"class_name\"] = patient_lvl[\"class\"].map(lambda x: class_names[x])\n",
    "\n",
    "patient_data = yolo_detection_df.groupby([\"Patient ID\"]).agg({\"COVID19\": \"first\", \"yolo_severity_score\": \"mean\", \"manual_severity_score\": \"mean\"}).reset_index()\n",
    "patient_lvl = pd.merge(patient_lvl, patient_data, on=\"Patient ID\").sort_values(by=[\"Patient ID\", \"class\"]).reset_index(drop=True)\n",
    "# Reorder columns\n",
    "patient_lvl = patient_lvl[[\"Patient ID\", \"COVID19\", \"yolo_severity_score\", \"manual_severity_score\", \"class\", \"class_name\", \"class_count\", \"class_count_conf_weighted\", \"area\", \"area_conf_weighted\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on all aggregation methods\n",
    "agg_eval = pd.DataFrame()\n",
    "agg_scores = pd.DataFrame()\n",
    "agg_methods = [#\"area\", \n",
    "            #\"area_conf_weighted\", \n",
    "            \"class_count\", \n",
    "            #\"class_count_conf_weighted\"\n",
    "            ]\n",
    "for agg_method in agg_methods:\n",
    "    # Pivot table for regression\n",
    "    class_area_per_patient_pivot = patient_lvl.pivot(index=\"Patient ID\", columns=\"class_name\", values=agg_method).reset_index()\n",
    "    class_area_per_patient_pivot = pd.merge(class_area_per_patient_pivot, patient_lvl[[\"Patient ID\" ,\"COVID19\"]], on=\"Patient ID\")\n",
    "    class_area_per_patient_pivot = class_area_per_patient_pivot.drop_duplicates().reset_index(drop=True)\n",
    "    # Shuffle\n",
    "    class_area_per_patient_pivot = class_area_per_patient_pivot.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "    # Use all classes for the model\n",
    "    X = class_area_per_patient_pivot[class_names]\n",
    "    y = class_area_per_patient_pivot[\"COVID19\"]\n",
    "\n",
    "    # Train models\n",
    "    scores, scores_mean = Classifier.train_models(X, y, plot=False)\n",
    "\n",
    "    # Add index level to df for aggregation\n",
    "    scores = pd.concat([scores], keys=[agg_method], names=['Aggregation method'])\n",
    "    scores_mean = pd.concat([scores_mean], keys=[agg_method], names=['Aggregation method'])\n",
    "    \n",
    "    # Add to dataframe\n",
    "    agg_scores = pd.concat([agg_scores, scores])\n",
    "    agg_eval = pd.concat([agg_eval, scores_mean])\n",
    "\n",
    "agg_eval.style.apply(highlight_max).format(\"{:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agg_eval.style.apply(highlight_max).format(\"{:.2f}\").to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [('area', 'class_count'),\n",
    "        # ('area_conf_weighted', 'area'),\n",
    "        # ('class_count_conf_weighted', 'class_count'),\n",
    "        ]\n",
    "\n",
    "scores_all_classes = agg_scores.reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.boxplot(data=scores_all_classes, x=\"Aggregation method\", y=\"test_accuracy\", palette=\"Set3\")\n",
    "add_stat_annotation(ax, data=scores_all_classes, x=\"Aggregation method\", y=\"test_accuracy\",\n",
    "                    box_pairs=pairs,\n",
    "                    test='Mann-Whitney', text_format='star', loc='outside', verbose=2)\n",
    "plt.title(\"Accuracy of different aggregation methods for all classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_mean = scores_all_classes[scores_all_classes[\"Aggregation method\"].isin([\"area\"])].mean().loc[\"test_accuracy\"]\n",
    "area_std = scores_all_classes[scores_all_classes[\"Aggregation method\"].isin([\"area\"])].std().loc[\"test_accuracy\"]\n",
    "class_count_mean = scores_all_classes[scores_all_classes[\"Aggregation method\"].isin([\"class_count\"])].mean().loc[\"test_accuracy\"]\n",
    "class_count_std = scores_all_classes[scores_all_classes[\"Aggregation method\"].isin([\"class_count\"])].std().loc[\"test_accuracy\"]\n",
    "\n",
    "print(f\"Area mean: {area_mean:.2f} +- {area_std:.2f}\")\n",
    "print(f\"Class count mean: {class_count_mean:.2f} +- {class_count_std:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the patient level improves the results significantly. Similarly to before try using only pathological classes for prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on all aggregation methods\n",
    "agg_eval = pd.DataFrame()\n",
    "agg_scores = pd.DataFrame()\n",
    "agg_methods = [\"area\", \n",
    "            \"area_conf_weighted\", \n",
    "            \"class_count\", \n",
    "            \"class_count_conf_weighted\"\n",
    "            ]\n",
    "for agg_method in agg_methods:\n",
    "    # Pivot table for regression\n",
    "    class_area_per_patient_pivot = patient_lvl.pivot(index=\"Patient ID\", columns=\"class_name\", values=agg_method).reset_index()\n",
    "    class_area_per_patient_pivot = pd.merge(class_area_per_patient_pivot, patient_lvl[[\"Patient ID\" ,\"COVID19\"]], on=\"Patient ID\")\n",
    "    class_area_per_patient_pivot = class_area_per_patient_pivot.drop_duplicates().reset_index(drop=True)\n",
    "    # Shuffle\n",
    "    class_area_per_patient_pivot = class_area_per_patient_pivot.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "    # Use all classes for the model\n",
    "    X = class_area_per_patient_pivot[pathological_class_names]\n",
    "    y = class_area_per_patient_pivot[\"COVID19\"]\n",
    "\n",
    "    # Train models\n",
    "    scores, scores_mean = Classifier.train_models(X, y, plot=False)\n",
    "\n",
    "    # Add index level to df for aggregation\n",
    "    scores = pd.concat([scores], keys=[agg_method], names=['Aggregation method'])\n",
    "    scores_mean = pd.concat([scores_mean], keys=[agg_method], names=['Aggregation method'])\n",
    "    \n",
    "    # Add to dataframe\n",
    "    agg_scores = pd.concat([agg_scores, scores])\n",
    "    agg_eval = pd.concat([agg_eval, scores_mean])\n",
    "\n",
    "agg_eval.style.apply(highlight_max).format(\"{:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeballing the results the filtering for only the pathological classes makes for a slight improvement on the patient level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_pathological_classes = agg_scores.reset_index()\n",
    "# Mann-Whitney U-Test\n",
    "x0 = scores_all_classes[\"test_accuracy\"]\n",
    "x1 = scores_pathological_classes[\"test_accuracy\"]\n",
    "stat, p_value = mannwhitneyu(x0, x1)\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "print(f\"Mean accuracy all classes: {x0.mean():.4f}\")\n",
    "print(f\"Mean accuracy pathological classes: {x1.mean():.4f}\")\n",
    "\n",
    "# Print green if p-value is significant otherwise red\n",
    "if p_value < 0.05:\n",
    "    print(\"\\033[92mSignificant difference\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[91mNo significant difference\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on all aggregation methods\n",
    "agg_eval = pd.DataFrame()\n",
    "agg_scores = pd.DataFrame()\n",
    "agg_methods = [\"area\", \n",
    "            \"area_conf_weighted\", \n",
    "            \"class_count\", \n",
    "            \"class_count_conf_weighted\"\n",
    "            ]\n",
    "for agg_method in agg_methods:\n",
    "    # Pivot table for regression\n",
    "    class_area_per_patient_pivot = patient_lvl.pivot(index=\"Patient ID\", columns=\"class_name\", values=agg_method).reset_index()\n",
    "    class_area_per_patient_pivot = pd.merge(class_area_per_patient_pivot, patient_lvl[[\"Patient ID\" ,\"COVID19\"]], on=\"Patient ID\")\n",
    "    class_area_per_patient_pivot = class_area_per_patient_pivot.drop_duplicates().reset_index(drop=True)\n",
    "    # Shuffle\n",
    "    class_area_per_patient_pivot = class_area_per_patient_pivot.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "    # Use all classes for the model\n",
    "    X = class_area_per_patient_pivot[non_pathological_class_names]\n",
    "    y = class_area_per_patient_pivot[\"COVID19\"]\n",
    "\n",
    "    # Train models\n",
    "    scores, scores_mean = Classifier.train_models(X, y, plot=False)\n",
    "\n",
    "    # Add index level to df for aggregation\n",
    "    scores = pd.concat([scores], keys=[agg_method], names=['Aggregation method'])\n",
    "    scores_mean = pd.concat([scores_mean], keys=[agg_method], names=['Aggregation method'])\n",
    "    \n",
    "    # Add to dataframe\n",
    "    agg_scores = pd.concat([agg_scores, scores])\n",
    "    agg_eval = pd.concat([agg_eval, scores_mean])\n",
    "\n",
    "agg_eval.style.apply(highlight_max).format(\"{:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_non_pathological_classes = agg_scores.reset_index()\n",
    "# Mann-Whitney U-Test\n",
    "x0 = scores_all_classes[\"test_accuracy\"]\n",
    "x1 = scores_non_pathological_classes[\"test_accuracy\"]\n",
    "stat, p_value = mannwhitneyu(x0, x1)\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "print(f\"Mean accuracy all classes: {x0.mean():.4f}\")\n",
    "print(f\"Mean accuracy non-pathological classes: {x1.mean():.4f}\")\n",
    "\n",
    "# Print green if p-value is significant otherwise red\n",
    "if p_value < 0.05:\n",
    "    print(\"\\033[92mSignificant difference\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[91mNo significant difference\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bluepoint information added to class area on video level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on all aggregation methods\n",
    "agg_eval = pd.DataFrame()\n",
    "agg_scores = pd.DataFrame()\n",
    "agg_methods = [\"area\", \n",
    "            \"area_conf_weighted\", \n",
    "            \"class_count\", \n",
    "            \"class_count_conf_weighted\"\n",
    "            ]\n",
    "for agg_method in agg_methods:\n",
    "    # Pivot table for regression\n",
    "    class_area_per_patient_pivot = patient_lvl.pivot(index=\"Patient ID\", columns=\"class_name\", values=agg_method).reset_index()\n",
    "    class_area_per_patient_pivot = pd.merge(class_area_per_patient_pivot, patient_lvl[[\"Patient ID\" ,\"COVID19\"]], on=\"Patient ID\")\n",
    "    class_area_per_patient_pivot = class_area_per_patient_pivot.drop_duplicates().reset_index(drop=True)\n",
    "    # Shuffle\n",
    "    class_area_per_patient_pivot = class_area_per_patient_pivot.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "    # Filter out video with Bluepoint == None\n",
    "    class_area_per_video_pivot = class_area_per_video_pivot[class_area_per_video_pivot[\"Bluepoint\"] != 'None']\n",
    "    # Get list of Bluepoint values\n",
    "    bluepoints = class_area_per_video_pivot.Bluepoint.unique().tolist()\n",
    "    bluepoints.sort()\n",
    "    # Create a dictionary for mapping Bluepoint values to integers\n",
    "    bp2code = {bp: i for i, bp in enumerate(bluepoints)}\n",
    "    code2bp = {i: bp for i, bp in enumerate(bluepoints)}\n",
    "    # Map Bluepoint values to integers \n",
    "    class_area_per_video_pivot[\"Bluepoint_codes\"] = class_area_per_video_pivot[\"Bluepoint\"].apply(lambda x: bp2code[x])\n",
    "\n",
    "    X = class_area_per_video_pivot[class_names + [\"Bluepoint_codes\"]]\n",
    "    y = class_area_per_video_pivot[\"COVID19\"]\n",
    "\n",
    "    # Train models\n",
    "    scores, scores_mean = Classifier.train_models(X, y, plot=False)\n",
    "\n",
    "    # Add index level to df for aggregation\n",
    "    scores = pd.concat([scores], keys=[agg_method], names=['Aggregation method'])\n",
    "    scores_mean = pd.concat([scores_mean], keys=[agg_method], names=['Aggregation method'])\n",
    "    \n",
    "    # Add to dataframe\n",
    "    agg_scores = pd.concat([agg_scores, scores])\n",
    "    agg_eval = pd.concat([agg_eval, scores_mean])\n",
    "\n",
    "agg_eval.style.apply(highlight_max).format(\"{:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_all_classes_plus_pb = agg_scores.reset_index()\n",
    "# Mann-Whitney U-Test\n",
    "x0 = scores_all_classes[\"test_accuracy\"]\n",
    "x1 = scores_all_classes_plus_pb[\"test_accuracy\"]\n",
    "stat, p_value = mannwhitneyu(x0, x1)\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "print(f\"Mean accuracy all classes: {x0.mean():.4f}\")\n",
    "print(f\"Mean accuracy classes + bp: {x1.mean():.4f}\")\n",
    "\n",
    "# Print green if p-value is significant otherwise red\n",
    "if p_value < 0.05:\n",
    "    print(\"\\033[92mSignificant difference\\033[0m\")\n",
    "else:\n",
    "    print(\"\\033[91mNo significant difference\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding information about where the video was taken interestingly does not improve the performance compared to the model simply using all pathological classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training one model per Bluepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bluepoint_models = pd.DataFrame()\n",
    "bluepoint_models_all = pd.DataFrame()\n",
    "for bp in bluepoints:\n",
    "    print(f\"Training model for {bp}...\")\n",
    "    bp_df = class_area_per_video_pivot[class_area_per_video_pivot[\"Bluepoint\"] == bp]\n",
    "    X = bp_df[class_names]\n",
    "    y = bp_df[\"COVID19\"]\n",
    "\n",
    "    scores, scores_mean = Classifier.train_models(X, y, plot=False)\n",
    "    scores = pd.concat([scores], keys=[bp], names=['Bluepoint'])\n",
    "    scores_mean = pd.concat([scores_mean], keys=[bp], names=['Bluepoint'])\n",
    "\n",
    "    bluepoint_models_all = pd.concat([bluepoint_models_all, scores])\n",
    "    bluepoint_models = pd.concat([bluepoint_models, scores_mean])\n",
    "\n",
    "\n",
    "bluepoint_models.style.apply(highlight_max).format(\"{:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bluepoint_models = bluepoint_models.reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = sns.boxplot(data=bluepoint_models, x=\"Bluepoint\", y=\"test_accuracy\", palette=\"Set3\")\n",
    "plt.title(\"Accuracy of different bluepoint model ensembles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning L1 and R1 to the bilateral bluepoint \"1\", L2 and R2 to \"2\" and L3 and R3 to \"3\" for aggregated plotting\n",
    "bluepoint_models[\"Bluepoint_bilateral\"] = bluepoint_models[\"Bluepoint\"].apply(lambda x: x[1])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.boxplot(data=bluepoint_models, x=\"Bluepoint_bilateral\", y=\"test_accuracy\", palette=\"Set3\")\n",
    "ax.set_xlabel(\"Bluepoint\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "# Display y ticks as percentage\n",
    "vals = ax.get_yticks()\n",
    "ax.set_yticklabels(['{:,.0%}'.format(x) for x in vals])\n",
    "plt.title(\"Accuracy of covEcho-based Bluepoint Models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannot import add_stat_annotation\n",
    "\n",
    "# Assigning L1 and R1 to the bilateral bluepoint \"1\", L2 and R2 to \"2\" and L3 and R3 to \"3\" for aggregated plotting\n",
    "bluepoint_models[\"Bluepoint_bilateral\"] = bluepoint_models[\"Bluepoint\"].apply(lambda x: x[1])\n",
    "\n",
    "pairs = [('1', '2'),\n",
    "        ('1', '3'),\n",
    "        ('2', '3'),\n",
    "        ]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = sns.boxplot(data=bluepoint_models, x=\"Bluepoint_bilateral\", y=\"test_accuracy\", palette=\"Set3\")\n",
    "add_stat_annotation(ax, data=bluepoint_models, x=\"Bluepoint_bilateral\", y=\"test_accuracy\",\n",
    "                    box_pairs=pairs,\n",
    "                    test='Mann-Whitney', text_format='star', loc='outside', verbose=0)\n",
    "plt.title(\"Accuracy of different bluepoint model ensembles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_left = bluepoint_models_all.loc[[\"L1\", \"L2\", \"L3\"]].test_accuracy\n",
    "bp_right = bluepoint_models_all.loc[[\"R1\", \"R2\", \"R3\"]].test_accuracy\n",
    "\n",
    "bp_1 = bluepoint_models_all.loc[[\"L1\", \"R1\"]].test_accuracy\n",
    "bp_2 = bluepoint_models_all.loc[[\"L2\", \"R2\"]].test_accuracy\n",
    "bp_3 = bluepoint_models_all.loc[[\"L3\", \"R3\"]].test_accuracy\n",
    "\n",
    "p_values = []\n",
    "\n",
    "# Mann-Whitney U-Test\n",
    "# stat, p_value = mannwhitneyu(bp_left, bp_right)\n",
    "# p_values.append(p_value)\n",
    "# print(\"Bluepoint left vs right\")\n",
    "# print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "# print(f\"Mean accuracy left: {bp_left.mean():.4f}\")\n",
    "# print(f\"Mean accuracy right: {bp_right.mean():.4f}\")\n",
    "\n",
    "print(\"Bluepoint 1 vs 2 vs 3\")\n",
    "print(\"1 vs 2\")\n",
    "stat, p_value = mannwhitneyu(bp_1, bp_2)\n",
    "p_values.append(p_value)\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "print(\"2 vs 3\")\n",
    "stat, p_value = mannwhitneyu(bp_2, bp_3)\n",
    "p_values.append(p_value)\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "print(\"1 vs 3\")\n",
    "stat, p_value = mannwhitneyu(bp_1, bp_3)\n",
    "p_values.append(p_value)\n",
    "print(f\"Mann–Whitney U Test: statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
    "\n",
    "print(\"\\n Means:\")\n",
    "print(f\"Mean accuracy 1: {bp_1.mean():.4f}\")\n",
    "print(f\"Mean accuracy 2: {bp_2.mean():.4f}\")\n",
    "print(f\"Mean accuracy 3: {bp_3.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using bonferonni correction for multiple comparisons\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "p_adjusted = multipletests(p_values, method='bonferroni')\n",
    "\n",
    "print(\"Bonferroni corrected p-values:\")\n",
    "\n",
    "test_distributions = [#\"L vs R\", \n",
    "                    \"1 vs 2\", \n",
    "                    \"2 vs 3\", \n",
    "                    \"1 vs 3\"]\n",
    "# Print green if p-value is significant otherwise red\n",
    "for i, p in enumerate(p_adjusted[1]):\n",
    "    if p < 0.05:\n",
    "        print(f\"\\033[92m{test_distributions[i]}: {p:.4f}\\033[0m\")\n",
    "    else:\n",
    "        print(f\"\\033[91m{test_distributions[i]}: {p:.4f}\\033[0m\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models trained on L1 and R1 perform significantly better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train only on BP 1 & 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out video with Bluepoint not L1 or R1\n",
    "yolo_detection_df_filtered = yolo_detection_df[yolo_detection_df[\"Bluepoint\"].isin([\"L1\", \"R1\", \"L3\", \"R3\"])]\n",
    "\n",
    "grp = yolo_detection_df_filtered.groupby([\"Patient ID\", \"class\"])\n",
    "patient_lvl = grp.agg({\"class\": \"count\", \"confidence\": \"sum\", \"area\": \"sum\", \"area_weighted\": \"sum\"})\n",
    "patient_lvl = patient_lvl.rename(columns={\"class\": \"class_count\", \"confidence\": \"class_count_conf_weighted\", \"area\": \"area\", \"area_weighted\": \"area_conf_weighted\"}).reset_index()\n",
    "\n",
    "# Add frame count\n",
    "frame_count_per_patient = yolo_detection_df_filtered[[\"Patient ID\", \"Bluepoint\", \"Frame\"]].drop_duplicates().groupby([\"Patient ID\"]).count().reset_index().rename(columns={\"Frame\": \"Frame_count\"}).drop(columns=[\"Bluepoint\"])\n",
    "patient_lvl = pd.merge(patient_lvl, frame_count_per_patient, on=\"Patient ID\")\n",
    "\n",
    "\n",
    "# Devide by frame count to get the average area per frame\n",
    "patient_lvl[\"area\"] = patient_lvl[\"area\"] / patient_lvl[\"Frame_count\"]\n",
    "patient_lvl[\"area_conf_weighted\"] = patient_lvl[\"area_conf_weighted\"] / patient_lvl[\"Frame_count\"]\n",
    "patient_lvl[\"class_count\"] = patient_lvl[\"class_count\"] / patient_lvl[\"Frame_count\"]\n",
    "patient_lvl[\"class_count_conf_weighted\"] = patient_lvl[\"class_count_conf_weighted\"] / patient_lvl[\"Frame_count\"]\n",
    "\n",
    "\n",
    "# Add classes with 0 area\n",
    "possible_classes = list(range(len(class_names)))\n",
    "patient_names = yolo_detection_df_filtered[\"Patient ID\"].unique().tolist()\n",
    "from itertools import product\n",
    "idx_df =  pd.DataFrame(list(product(possible_classes, patient_names))).rename(columns={0:'class',1:'Patient ID'})\n",
    "\n",
    "patient_lvl = pd.merge(idx_df, patient_lvl, on=[\"Patient ID\", \"class\"], how=\"left\").fillna(0).sort_values(by=[\"Patient ID\", \"class\"])\n",
    "\n",
    "patient_lvl[\"class_name\"] = patient_lvl[\"class\"].map(lambda x: class_names[x])\n",
    "\n",
    "patient_data = yolo_detection_df_filtered.groupby([\"Patient ID\"]).agg({\"COVID19\": \"first\", \"yolo_severity_score\": \"mean\", \"manual_severity_score\": \"mean\"}).reset_index()\n",
    "patient_lvl = pd.merge(patient_lvl, patient_data, on=\"Patient ID\").sort_values(by=[\"Patient ID\", \"class\"]).reset_index(drop=True)\n",
    "# Reorder columns\n",
    "patient_lvl = patient_lvl[[\"Patient ID\", \"COVID19\", \"yolo_severity_score\", \"manual_severity_score\", \"class\", \"class_name\", \"class_count\", \"class_count_conf_weighted\", \"area\", \"area_conf_weighted\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on all aggregation methods\n",
    "agg_eval = pd.DataFrame()\n",
    "agg_scores = pd.DataFrame()\n",
    "agg_methods = [\"area\", \n",
    "            #\"area_conf_weighted\", \n",
    "            \"class_count\", \n",
    "            #\"class_count_conf_weighted\"\n",
    "            ]\n",
    "for agg_method in agg_methods:\n",
    "    # Pivot table for regression\n",
    "    class_area_per_patient_pivot = patient_lvl.pivot(index=\"Patient ID\", columns=\"class_name\", values=agg_method).reset_index()\n",
    "    class_area_per_patient_pivot = pd.merge(class_area_per_patient_pivot, patient_lvl[[\"Patient ID\" ,\"COVID19\"]], on=\"Patient ID\")\n",
    "    class_area_per_patient_pivot = class_area_per_patient_pivot.drop_duplicates().reset_index(drop=True)\n",
    "    # Shuffle\n",
    "    class_area_per_patient_pivot = class_area_per_patient_pivot.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "    # Use all classes for the model\n",
    "    X = class_area_per_patient_pivot[class_names]\n",
    "    y = class_area_per_patient_pivot[\"COVID19\"]\n",
    "    # groups = class_area_per_patient_pivot[\"Patient ID\"]\n",
    "\n",
    "    # Train models\n",
    "    scores, scores_mean = Classifier.train_models(X, y, \n",
    "                                                # groups=groups, \n",
    "                                                plot=False)\n",
    "    \n",
    "    # Add index level to df for aggregation\n",
    "    scores = pd.concat([scores], keys=[agg_method], names=['Aggregation method'])\n",
    "    scores_mean = pd.concat([scores_mean], keys=[agg_method], names=['Aggregation method'])\n",
    "    \n",
    "    # Add to dataframe\n",
    "    agg_scores = pd.concat([agg_scores, scores])\n",
    "    agg_eval = pd.concat([agg_eval, scores_mean])\n",
    "\n",
    "agg_eval.style.apply(highlight_max).format(\"{:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agg_eval.style.apply(highlight_max).format(\"{:.2f}\").to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, only training on L1 and R1 does not seem to improve the overall model performance however."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi class classification for manual severity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import ml_pipeline\n",
    "importlib.reload(ml_pipeline)\n",
    "from ml_pipeline import ModelEvaluation\n",
    "\n",
    "\n",
    "Multi_Classifier = ModelEvaluation(mode=\"classification_multi_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table for regression\n",
    "class_area_per_video_pivot = video_level.pivot(index=\"video_name\", columns=\"class_name\", values=\"class_count\").reset_index()\n",
    "class_area_per_video_pivot = pd.merge(class_area_per_video_pivot, video_level[[\"video_name\", \"COVID19\", \"Bluepoint\", \"Patient ID\", \"manual_severity_score\"]], on=\"video_name\")\n",
    "class_area_per_video_pivot = class_area_per_video_pivot.drop_duplicates().reset_index(drop=True)\n",
    "# Shuffle\n",
    "class_area_per_video_pivot = class_area_per_video_pivot.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "class_area_per_video_pivot = class_area_per_video_pivot.dropna(subset=[\"manual_severity_score\"])\n",
    "video_lvl = class_area_per_video_pivot\n",
    "# Split into X and y\n",
    "X = video_lvl[class_names]\n",
    "y = video_lvl[\"manual_severity_score\"]\n",
    "groups = video_lvl[\"Patient ID\"]\n",
    "\n",
    "# Train models\n",
    "scores, scores_mean = Multi_Classifier.train_models(X, y, groups=groups)\n",
    "\n",
    "scores_mean.style.apply(highlight_max).format(\"{:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_mean to latex format .2f\n",
    "print(scores_mean.style.format(\"{:.2f}\").to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table for regression\n",
    "class_area_per_patient_pivot = patient_lvl.pivot(index=\"Patient ID\", columns=\"class_name\", values=\"class_count\").reset_index()\n",
    "class_area_per_patient_pivot = pd.merge(class_area_per_patient_pivot, patient_lvl[[\"Patient ID\" ,\"COVID19\", \"manual_severity_score\"]], on=\"Patient ID\")\n",
    "class_area_per_patient_pivot = class_area_per_patient_pivot.drop_duplicates().reset_index(drop=True)\n",
    "# Shuffle\n",
    "class_area_per_patient_pivot = class_area_per_patient_pivot.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "# Cast manual severity score to int\n",
    "class_area_per_patient_pivot[\"manual_severity_score\"] = class_area_per_patient_pivot[\"manual_severity_score\"].astype(int)\n",
    "# Split into X and y\n",
    "X = class_area_per_patient_pivot[class_names]\n",
    "y = class_area_per_patient_pivot[\"manual_severity_score\"]\n",
    "\n",
    "# Train models\n",
    "scores_patient, scores_mean_patient = Multi_Classifier.train_models(X, y)\n",
    "\n",
    "scores_mean_patient.style.apply(highlight_max).format(\"{:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_mean to latex format .2f\n",
    "print(scores_mean_patient.style.format(\"{:.2f}\").to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores_mean and scores_mean_patient in one dataframe\n",
    "# Add index level to df for aggregation\n",
    "scores_mean = pd.concat([scores_mean], keys=[\"Video\"], names=['Level'])\n",
    "scores_mean_patient = pd.concat([scores_mean_patient], keys=[\"Patient\"], names=['Level'])\n",
    "# Concatenate\n",
    "scores_mean = pd.concat([scores_mean, scores_mean_patient])\n",
    "\n",
    "grouped = scores_mean.groupby(\"Level\")\n",
    "max_index = grouped[\"test_accuracy\"].idxmax()\n",
    "best_models = scores_mean.loc[max_index].sort_values(\"test_accuracy\", ascending=False)\n",
    "best_models.index = best_models.reset_index().Level + \" (\" + best_models.reset_index().model + \")\"\n",
    "\n",
    "best_models.plot.bar()\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "best_models.style.apply(highlight_max).format(\"{:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_models.style.format(\"{:.2f}\").to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pocovid2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b946eb799261426a5ad5f24f4c27986c0f2fe154ec5ad35bd8b05c7d39be50ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
